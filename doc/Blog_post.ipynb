{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Will the Stadium be Buzzing or Silent?\n",
        "subtitle: Demand of Attendance for European Football Leagues\n",
        "author: Matthew Wilcox\n",
        "bibliography: references.bib\n",
        "number-sections: false\n",
        "format:\n",
        "  html:\n",
        "    theme: default\n",
        "    toc: true\n",
        "    rendering: default\n",
        "    code-fold: true\n",
        "    code-tools: true\n",
        "    warning: false\n",
        "  pdf: default\n",
        "---"
      ],
      "id": "6487a03e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](Header Image/victoria-prymak-CCe_Xt5sEDA-unsplash.jpg)\n",
        "\n",
        "\n",
        "\n",
        "# Why Attendance Matters \n",
        "\n",
        "Football (Soccer) is the most popular sport in the world. With an estimated 3.5 billion fans worldwide, it is the most viewed sport in the world [@sportforbusiness]. Football being such a popular sport, there is a large business and economy surrounding the sport. Football teams need to be profitable to succeed. But how do these teams make money? Well mainly from 5 different sources being: television money, prize money, player transfers, sponsorships, and matchday revenues[@football_stadiums]. Out of all of these, one of the most universal is matchday revenues.  For many teams, the match day revnue is the lifeblood of the club and what allows the club to survive. \n",
        "\n",
        "The attendnace of a match significantly affect the match day revenues. So understanding factors and predicting the attendance for a given match is increasingly important. If a club could predict the number of people attending a match, they could be better prepared for an individual match such as if it is expected to have lower attendance than desired by the club, the club could market it differently or have special promotions to increase the attendance for that match. \n",
        "\n",
        "There are many factors that could impact the attendance of a match. However, the factors used and evaluated here are the day/time of the match, betting odds for a match, and who the away team is for any given match. Additionally, in the end, a random forest model was produced to predict the attendance of matches based on these factors. \n",
        "\n",
        "# Python Packages Used\n"
      ],
      "id": "b065e7c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "#| code-summary: \"Library Packages\"\n",
        "#| echo: true\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import july\n",
        "from datetime import datetime as dt\n",
        "from jupyter_dash import JupyterDash\n",
        "from dash import html, dcc, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime, time\n",
        "from re import sub\n",
        "import re\n",
        "import plotly.express as px\n",
        "import pickle"
      ],
      "id": "e4431501",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection\n",
        "\n",
        "This project used datat that was collected from two sources: worldfootball.net and Football-data.co.uk. The data that was collected from worldfootball.net was information on the match, such as the names of the teams, the time and date of the match, and most importantly, the attendance for an individual match. This data was scraped from the website. This scrape occurred on January 31st, 2023. The data that was collected from Football-data.co.uk was primarily betting information for each game. This data was already tabulated into CSV files. However, they were divided based on the year and league. All the files were downloaded on February 3rd, 2023.\n",
        "\n",
        "The data that was collected was between 2010 and 2023. It consisted of leagues from 11 countries England, Scotland, Germany, Italy, Spain, France, Netherlands, Belgium, Portugal, Turkey, and Greece. From these Countries, 21 leagues of data were collected.\n",
        "\n",
        "# Data Processing\n"
      ],
      "id": "8ec5a16f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "betting_data = pd.read_csv('../data/RAWDATA/RAW_betting_data.csv')\n",
        "match_data =  pd.read_csv('../data/RAWDATA/RAW_match_data.csv')\n",
        "with open('../src/Data_Processing/key_dictionary.pkl', 'rb') as pick:\n",
        "    key_dict = pickle.load(pick)\n",
        "def snake_case(s):\n",
        "  return '_'.join(\n",
        "    sub('([A-Z][a-z]+)', r' \\1',\n",
        "    sub('([A-Z]+)', r' \\1',\n",
        "    s.replace('-', ' '))).split()).lower()\n",
        "betting_data['HomeTeam'] =betting_data['HomeTeam'].apply(str)\n",
        "betting_data['HomeTeam'] =betting_data['HomeTeam'].apply(snake_case)\n",
        "betting_data['AwayTeam'] =betting_data['AwayTeam'].apply(str)\n",
        "betting_data['AwayTeam'] =betting_data['AwayTeam'].apply(snake_case)\n",
        "\n",
        "betting_data['HomeTeam'] = betting_data['HomeTeam'].replace(key_dict)\n",
        "betting_data['AwayTeam'] = betting_data['AwayTeam'].replace(key_dict)\n",
        "\n",
        "match_data['home_team'] =match_data['home_team'].apply(str)\n",
        "match_data['home_team'] =match_data['home_team'].apply(snake_case)\n",
        "match_data['away_team'] =match_data['away_team'].apply(str)\n",
        "match_data['away_team'] =match_data['away_team'].apply(snake_case)\n",
        "\n",
        "match_data['Hohome_teammeTeam'] = match_data['home_team'].replace(key_dict)\n",
        "match_data['away_team'] = match_data['away_team'].replace(key_dict)\n",
        "\n",
        "# betting_data.to_pickle('data/Data_to_change/betting_data_updated_names.pkl')\n",
        "# match_data.to_pickle('data/Data_to_change/match_data_updated_names.pkl')"
      ],
      "id": "0fcda3d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# match_data = pd.read_pickle('data/Data_to_change/match_data_updated_names.pkl')\n",
        "# betting_data = pd.read_pickle('data/Data_to_change/betting_data_updated_names.pkl')\n",
        "# print(match_data)\n",
        "\n",
        "month_key = {'August': '8', 'September':'9', 'October':'10', 'November': '11','December':'12', 'January':'1', 'February':'2', 'March':'3', 'April':'4', 'May':'5', 'June' : '6', 'July':'7'}\n",
        "\n",
        "match_data['month']= match_data['month'].replace(month_key)\n",
        "\n",
        "match_data['date'] = match_data['day_of_month'].astype(str) + \"-\" + match_data['month'].astype(str) + \"-\" + match_data['year'].astype(str)\n",
        "\n",
        "match_data['date'] = pd.to_datetime(match_data['date'])\n",
        "betting_data['Date'] = pd.to_datetime(betting_data['Date'])\n",
        "# print(betting_data)\n",
        "# print(match_data)\n",
        "# print(betting_data.dtypes)\n",
        "# print(match_data.dtypes)\n",
        "\n",
        "# # match_data.to_pickle('data/Data_to_change/match_data_updated_date.pkl')\n",
        "# # betting_data.to_pickle('data/Data_to_change/betting_data_updated_date.pkl')"
      ],
      "id": "6452ab5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# # match_data = pd.read_pickle('data/Data_to_change/match_data_updated_date.pkl')\n",
        "# # betting_data = pd.read_pickle('data/Data_to_change/betting_data_updated_date.pkl')\n",
        "# print(match_data)\n",
        "# print(betting_data)\n",
        "\n",
        "\n",
        "merged_df = pd.merge(match_data, betting_data, left_on = ['date', 'home_team', 'away_team'], right_on = ['Date', 'HomeTeam', 'AwayTeam'], how ='left', indicator=False)\n",
        "\n",
        "# print(merged_df)"
      ],
      "id": "dfb36425",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# merged_df.to_pickle('data/Data_to_change/betting_and_match_data.pkl')\n",
        "# merged_df.to_csv('data/Data_to_change/betting_and_match_data.csv')\n",
        "\n",
        "# data = pd.read_pickle('data/Data_to_change/complete_data.pkl')\n",
        "data = merged_df\n",
        "data = data[data['year']<= 2019]\n",
        "# data.to_pickle('data/Data_to_change/complete_data_before_2019.pkl')\n",
        "# data.to_csv('data/Data_to_change/complete_data_before_2019.csv')"
      ],
      "id": "72389b33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# data = pd.read_pickle('data/Data_to_change/complete_data_before_2019.pkl')\n",
        "\n",
        "\n",
        "data = data[['home_team','away_team','home_score','away_score','date','time','day_of_week','attendance','Div','FTHG','FTAG','FTR','HTHG','HTAG','HTR','B365H','B365D','B365A','BWH','BWD','BWA','WHH','WHD','WHA','VCH','VCD','VCA','BbMx>2.5','BbAv>2.5','BbMx<2.5','BbAv<2.5']]\n",
        "\n",
        "# print(data)\n",
        "\n",
        "\n",
        "# data.to_pickle(\"data/Data_to_change/complete_data_2010_2019_shrunk.pkl\")\n",
        "# data.to_csv(\"data/Data_to_change/complete_data_2010_2019_shrunk.csv\")\n",
        "\n",
        "# data = pd.read_pickle('data/Data_to_change/complete_data_2010_2019_shrunk.pkl')\n",
        "\n",
        "# for col in data.columns:\n",
        "    # print(col)\n",
        "\n",
        "data = data.rename(columns = {'attendance':'raw_attendance'})\n",
        "# data['Capacity'] = data['Capacity'].astype(str)\n",
        "\n",
        "# data.loc[data.url == 'https://www.worldfootball.net/venues/mersin-arena-mersin/', 'Capacity'] = '25534'\n",
        "# data.loc[data.url == 'https://www.worldfootball.net/venues/stade-paul-lignon-rodez/', 'Capacity'] = '5955'\n",
        "\n",
        "\n",
        "# df2 = data[data['away_score'].str.contains('\\d')]\n",
        "# print(df2)\n",
        "# df2.to_csv('src/Data_processing/missing_capicty.csv')"
      ],
      "id": "e9d5fcce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = data[data['raw_attendance'].str.contains('\\d')]\n",
        "data['raw_attendance'] = data['raw_attendance'].astype(float)\n",
        "# data['Capacity'] = data['Capacity'].astype(float)\n",
        "\n",
        "def remove_non_numberics(s):\n",
        "    return sub('[^0-9]', '', s)\n",
        "\n",
        "data['away_score'] = data['away_score'].apply(lambda x: re.sub('[^0-9]', '', x))\n",
        "\n",
        "# print(df2['Capacity'])\n",
        "# for index, row in data.iterrows():\n",
        "#     if row['check_raw'] == 'str'\n",
        "# print(data[['Capacity', 'raw_attendance']])\n",
        "\n",
        "\n",
        "# print(data[['raw_attendance', 'Capacity']].dtypes)\n",
        "# data['capacity_filled'] = data['raw_attendance']/data['Capacity']\n",
        "# data['capacity_filled'] = data['capacity_filled'].round(4)\n",
        "\n",
        "\n",
        "# Alter Data types:\n",
        "data= data.rename(columns={ 'Div':'division'})\n",
        "data['home_score']= data['home_score'].astype(int)\n",
        "data['away_score'] = data['away_score'].astype(int)\n",
        "data['date'] = data['date'].astype(str)\n",
        "# data['time'] = data['time'].apply(lambda x: datetime.strptime(x, '%H:%M'))\n",
        "data['date_time'] = data.apply(lambda row: pd.to_datetime(str(row['date']) + ' ' + str(row['time'])),axis = 1)\n",
        "data['raw_attendance']= data['raw_attendance'].astype(int)\n",
        "# print(data)\n",
        "\n",
        "# data.to_pickle('data/final_datasets/Total_data.pkl')\n",
        "\n",
        "# data.to_csv('data/final_datasets/Total_data.csv')"
      ],
      "id": "cc98803c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# data = pd.read_pickle('data/final_datasets/Total_data.pkl')\n",
        "\n",
        "season = []\n",
        "for index, rows in data.iterrows():\n",
        "    match_day = dt.strptime(rows['date'], '%Y-%m-%d')\n",
        "    # print(match_day)\n",
        "    year = int(dt.strftime(match_day, '%Y'))\n",
        "    month_day = dt.strftime(match_day, '%m-%d')\n",
        "    # print(int(year))\n",
        "    # print(type(year))\n",
        "    # print(month_day)\n",
        "    cutoff_date = dt.strftime(dt(2014,7,14), '%m-%d')\n",
        "    if month_day > cutoff_date:\n",
        "        year = year +1\n",
        "        season = season + [year]\n",
        "\n",
        "    else:\n",
        "        season = season + [year]\n",
        "\n",
        "# def stand_dev(x): return np.std(x)\n",
        "\n",
        "data['season'] = season\n",
        "\n",
        "data_std = data.groupby(['home_team', 'season'])['raw_attendance'].std().reset_index()\n",
        "# print(data_std)\n",
        "data_std = data_std.rename(columns = {'raw_attendance':'std_attend'})\n",
        "# print(data_std[data_std['std_attend'].isna()])\n",
        "data_mean = data.groupby(['home_team', 'season']).mean().reset_index()\n",
        "data_mean = data_mean[['home_team', 'season', 'raw_attendance']].rename(columns = {'raw_attendance': 'mean_attend'})\n",
        "data = pd.merge(data, data_mean, on = ['home_team', 'season'])\n",
        "total_data = pd.merge(data, data_std, on= ['home_team', 'season'])\n",
        "total_data['standard_attend'] = (total_data['raw_attendance']-total_data['mean_attend'])/ total_data['std_attend']\n",
        "# data.to_pickle('data/final_datasets/data_standardized.pkl')\n",
        "# data.to_csv('data/final_datasets/data_standardized.csv')"
      ],
      "id": "c6e995b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All of the CSV files from Football-data.co.uk were combined together, resulting in two datasets. One with all of the betting data and the other with the attendance. To create one final dataset, the two datasets were to be combined on the home team name, away team name, and the date/time of the game. However, issues arose as they had different naming structures for team names. For example, the team Manchester City in one dataset would be identified as \"man_city\" and in the other as \"manchester_city\". With these differentiating structures and spellings of team names, a list of team names was created for both datasets. These lists were then put through a python script that took a team from one list and compared the characters to values in the other list. This was starting with one entire team name and slowly decreasing its size and observing that through the other team list. \n",
        "\n",
        "|Itteration| Results|\n",
        "|----|-----|\n",
        "|1| man_city|\n",
        "|2| man_cit, an_city|\n",
        "|3| man_ci, an_cit, n_city|\n",
        "|4| man_c, an_ci, n_cit, _city|\n",
        "\n",
        "![](Header Image/name_compare.gif)\n",
        "\n",
        "\n",
        "This is an example of how it would split up one team name into a list of smaller strings. It would do this until the team list was broken up into single characters. Then it would start with the largest length of a team name, looking through the other list for any matching character combinations. What resulted is a list of potential matching teams with the team with the most similar name at the top. Then I would determine from the suggestion what was the matching team name. Now that the two data sets had a matching naming of home and away teams, the data sets were able to combine. The resulting data set had 79673 rows and 172 columns, where each row was an individual match. \n",
        "\n",
        "However, more processing was needed. Although the initial dataset collected data all the way to 2023, the range of the data was filtered to only 2010 to 2019. This was attributed to the COVID-19 pandemic. During the pandemic, attendance basically ceased to occur for matches. Additionally, some leagues canceled the remaining matches for the season. For those reasons, the dataset is focused up until that time. \n",
        "\n",
        "Certain leagues were removed from the dataset for analysis. The Scottish Division 2 and Division 3 leagues, as well as the Ethniki Katigoria, which is the Greek top league, were removed. This is due to them having several missing values for many variables. Some matches from a variety of leagues had missing values for only betting variables. These matches within leagues were used during the analysis of day/time and the impact of the away team. However, they were dropped from the dataset for analysis of betting data and in the modeling. \n",
        "\n",
        "Lastly, a few new variables were added. The first variable added was the season the match occurred. Although leagues end on different dates in different years, the date selected for the season to switch was July 14th. Most leagues conclude at the beginning of June and start back at the beginning of August. July is predominantly used for international games. Although there were a couple of matches that occurred in July from 2010-2019, July 14th was the only date with zero matches played. So it was used as the cutoff point. \n",
        "\n",
        "The other variables were the mean and standard deviation of the home team for that season and the z-score of that individual match. The mean and standard deviation were just used to create the z-score variable. The z-score is the standardization of the match's attendance in relation to the home team's average attendance for that particular season. \n",
        "\n",
        "\n",
        "## Final Dataset\n",
        "\n",
        "The resulting dataset that was used consisted of 53,224 rows and 29 columns. Descriptions of variables can be viewed in the [data dictionary](https://matthewlwilcox.github.io/Capstone/doc/data_dictionary.html).\n"
      ],
      "id": "08a6f36b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Data Import\"\n",
        "# total_data = data\n",
        "total_data = total_data[['home_team', 'away_team',  'date', 'time',\n",
        "       'day_of_week', 'raw_attendance', 'division',  'FTR',\n",
        "       'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA',\n",
        "       'WHH', 'WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'BbMx>2.5', 'BbAv>2.5',\n",
        "       'BbMx<2.5', 'BbAv<2.5', 'date_time', 'season', 'mean_attend',\n",
        "       'std_attend', 'standard_attend']]\n",
        "total_data.head()\n",
        "# total_data.columns\n",
        "# total_data = pd.read_pickle('../data/final_datasets/data_standardized.pkl')"
      ],
      "id": "eb282a39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Date & Time\n",
        "\n",
        "The first factor that will be evaluated is the date and time of individual matches. There are multiple attributes to this that will be viewed, from the day of the week, calendar date, and time of the match.\n"
      ],
      "id": "5ddce60f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Time Data Processing\"\n",
        "#| warning: false\n",
        "\n",
        "time_df = total_data[[\n",
        "    'date', 'time', 'day_of_week', 'date_time', 'raw_attendance', 'standard_attend', 'division'\n",
        "]]\n",
        "div_dict = {'D1':'Bundesliga', 'D2': '2. Bundesliga', 'E0':'Premier League', 'E1':'Championship', \n",
        "            'E2':'League 1', 'E3':'Leauge 2','SP1':'La Liga Primera', 'SP2':'La Liga Segunda',\n",
        "              'B1':'Jupiler League', 'F1':'Ligue 1','F2':'Ligue 2','I1':'Serie A','I2':'Seire B', \n",
        "              'SC0':'Scotish Premier League', 'SC1':'Scotish Division 1', 'T1':'Fubol Ligi 1', 'P1': 'Liga 1'}\n",
        "divisions_list =['D1', 'D2', 'E0', 'E1', 'E2', 'E3', 'SP1' ,'SP2', 'B1', 'F1', 'F2', 'I1', 'I2', 'SC0', 'SC1', 'T1', 'P1']\n",
        "\n",
        "df_grouped_mean = time_df.groupby('day_of_week')['raw_attendance',  'standard_attend'].mean().reset_index()\n",
        "df_grouped_median = time_df.groupby('day_of_week')['raw_attendance',  'standard_attend'].median().reset_index()\n",
        "\n",
        "day_categories = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "df_grouped_median['day_of_week'] = pd.Categorical(df_grouped_median['day_of_week'], categories= day_categories)\n",
        "df_grouped_median.sort_values(by = 'day_of_week', inplace = True)"
      ],
      "id": "594894be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Day of Week\n",
        "\n",
        "First, in @fig-day_median_attend, the average attendance for matches is viewed by the day of the week. What is significant here is that it appears that Wednesday and Sunday have the highest average attendance while Tuesday has the lowest. Wednesday having the highest average attendance is striking. Most would expect matches on the weekdaywould struggle to have high attendance. \n"
      ],
      "id": "75d429db"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-day_median_attend\n",
        "#| fig-cap: Median Attendnace by day of the week\n",
        "#| code-fold: true\n",
        "#| code-summary: Day of the Week Standardized Median\n",
        "\n",
        "\n",
        "sns.barplot(data=df_grouped_median, x = 'day_of_week', y = 'raw_attendance').set(title ='Median  Attendance by Day of Week')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Median Attendance')\n",
        "plt.show()\n"
      ],
      "id": "fig-day_median_attend",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The @fig-day_median_attend graph had Saturday lower than expected average attendance, with Wednesday having the most games attended on average due to the distribution of the number of games seen in @fig-count_day. Saturday has by far the most amount of games in comparison to any day of the week. This results in Saturday having more lower attend games from lower leagues. This is confirmed by @fig-day_median_attend_div. Looking at the number of games by leagues on Saturday, it had most of the lower leagues host matches on Saturday than other days of the week. Wednesday has the second-fewest games played; however, looking again at @fig-day_median_attend_div, it was predominantly composed of the top leagues in England, France, and Italy. The top leagues, on average, have greater attended games; hence Wednesday on average has the highest attendance on average. \n"
      ],
      "id": "a631e612"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Day of the Week total Count\n",
        "#| label: fig-count_day\n",
        "#| fig-cap: Number of games per day of the week\n",
        "grouped_week_count = time_df.groupby('day_of_week').count().reset_index()\n",
        "\n",
        "grouped_week_count['day_of_week'] = pd.Categorical(grouped_week_count['day_of_week'], categories= day_categories)\n",
        "grouped_week_count.sort_values(by = 'day_of_week', inplace = True)\n",
        "\n",
        "\n",
        "sns.barplot(data = grouped_week_count, x = 'day_of_week', y = 'date')\n",
        "plt.xlabel('Day of the Week')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of games per day of the Week')\n",
        "plt.show()\n"
      ],
      "id": "fig-count_day",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-day_median_attend_div\n",
        "#| fig-cap: Number of games per day of week divided by League\n",
        "grouped_week_count_division =  time_df.groupby(['day_of_week', 'division']).count().reset_index()\n",
        "\n",
        "grouped_week_count_division['day_of_week'] = pd.Categorical(grouped_week_count_division['day_of_week'], categories= day_categories)\n",
        "grouped_week_count_division.sort_values(by = 'day_of_week', inplace = True)\n",
        "grouped_week_count_division = grouped_week_count_division[['day_of_week', 'division', 'date']]\n",
        "\n",
        "\n",
        "total_div_number = grouped_week_count_division.groupby('day_of_week').sum().reset_index()\n",
        "# print(total_div_number)\n",
        "rose_df = pd.merge(grouped_week_count_division, total_div_number, on= 'day_of_week')\n",
        "rose_df['pct'] = rose_df['date_x']/rose_df['date_y']\n",
        "# print(rose_df)\n",
        "rose_df['League'] = rose_df['division']\n",
        "rose_df = rose_df.replace({'League':div_dict})\n",
        "rose_df\n",
        "fig = px.bar_polar(rose_df, theta = 'day_of_week', r = 'pct', color = 'League')\n",
        "fig.show()\n"
      ],
      "id": "fig-day_median_attend_div",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time of Day\n"
      ],
      "id": "129bdf44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Attendance Time of Day\"\n",
        "\n",
        "\n",
        "df_grouped_mean_tod= time_df.groupby(time_df['date_time'].dt.hour).mean()\n",
        "df_grouped_median_tod= time_df.groupby(time_df['date_time'].dt.hour).median()\n",
        "\n",
        "\n",
        "# sns.lineplot(data = df_grouped_median_tod, x = 'date_time', y = 'raw_attendance', markers = True, marker = \"o\" )\n",
        "# plt.title('Attendance by Time of Day')\n",
        "# plt.xlabel('Hour of the Day')\n",
        "# plt.ylabel('Attendance')\n",
        "# plt.show()"
      ],
      "id": "cbb14651",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The time and day of a match resulted in a similar situation as the day of the week. In @fig-attendance_time, there were dips in attendance at 3 pm and 9 pm; however, these were also the most attended times for matches. 12 pm and 11 pm matches had the highest attendance on average however had a lower amount of games. \n"
      ],
      "id": "fb1d6f37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: Number of Games Time of Day\n",
        "#| label: fig-attendance_time\n",
        "#| fig-cap: Attendance and Match count by time of day\n",
        "df_grouped_count = time_df.groupby(time_df['date_time'].dt.hour).count()\n",
        "# print(df_grouped_count)\n",
        "df_grouped_count = df_grouped_count['raw_attendance'].reset_index()\n",
        "df_grouped_count['count'] = df_grouped_count['raw_attendance']\n",
        "df_grouped_count = df_grouped_count[['date_time', 'count']]\n",
        "# df_grouped_count= df_grouped_count.rename(columns = {'date':'count'})\n",
        "# print(df_grouped_count)\n",
        "\n",
        "df_count_atted = pd.merge(df_grouped_count, df_grouped_median_tod, on = 'date_time')\n",
        "# df_count_atted = df_count_atted.drop(columns= ['capacity_filled'])\n",
        "df_count_atted.rename( columns = {'raw_attendance': 'Attendance', 'count': \"Number of Games\"}, inplace= True)\n",
        "# print(df_count_atted)\n",
        "melted_count_attend = pd.melt(df_count_atted, value_vars=['Number of Games', 'Attendance'], id_vars= 'date_time')\n",
        "# print(melted_count_attend)\n",
        "\n",
        "sns.lineplot(data = melted_count_attend, x = 'date_time', y = 'value', hue = 'variable')\n",
        "plt.title('Attendance and Game Count by Time of Day')\n",
        "plt.xlabel('Hour of the Day')\n",
        "\n",
        "plt.show()"
      ],
      "id": "fig-attendance_time",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calendar Date\n",
        "\n",
        "The last aspect of when the match occurred evaluated was what day of the year the match occurred. This is viewing trends during the calendar year to see if there is any insight. \n"
      ],
      "id": "5fd2eb87"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "calendar_plot_data = total_data\n",
        "calendar_plot_data['month_day'] = calendar_plot_data['date_time'].dt.strftime('%m-%d')\n"
      ],
      "id": "c9db11b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trends in Quanity of Matches\n",
        "\n",
        "Before looking at the attendance, it's important to look at and view trends in when matches actually occur. In @fig-cal_count, there is a significantly low amount of games played from mid-June to the end of July. This can most likely be attributed to European leagues predominantly being on break during these months in relation to FIFA international break. On this break, players typically return to their national teams to play in international competitions and, every four years, the world cup. Another significant period of time for a number of games is the Christmas holiday. Christmas has one of the lowest total number of games occurring. However, December 26th, or Boxing Day, had the most amount of games played for any day. \n"
      ],
      "id": "d695c75d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-cal_count\n",
        "#| fig-cap: Calendar Plot of total Number of Matches\n",
        "#| warning: false\n",
        "\n",
        "date_of_year = calendar_plot_data.groupby('month_day').count()\n",
        "date_of_year['count'] = date_of_year['standard_attend']\n",
        "date_of_year = date_of_year['count'].sort_values().reset_index()\n",
        "# print(date_of_year)\n",
        "date_of_year['total_date'] = '2024-' + date_of_year['month_day']\n",
        "date_of_year['total_date']= pd.to_datetime(date_of_year['total_date'], format = \"%Y-%m-%d\")\n",
        "events = pd.Series(date_of_year['count'].values.tolist(), index = date_of_year['total_date'].values.tolist())\n",
        "july.heatmap(dates = date_of_year['total_date'], data = date_of_year['count'],  date_label = True, cmap = 'RdYlBu', fontsize =10, weekday_label=False, year_label= False, title = '# of Games per day 2010-2019', colorbar= True, dpi =1200)\n",
        "plt.show()"
      ],
      "id": "fig-cal_count",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trends in Attedance of matches. \n",
        "\n",
        "Now looking at the attendance for these matches based on their calendar date, some trends appear. First, there is a grouping of higher-than-average attended matches in May. This can most likely be attributed to the seasons across Europe finishing. In turn, these matches have a higher weight to them due to their ramifications of them. For teams at the top and bottom of the standings, these matches have massive implications for the club. They can result in the team being promoted (moved up a league) or relegated (moved down a league) and having access to European competition. Additionally, with holidays there is an effect on attendance. First, November 6th, which is All Saint's Day, saw a decrease in attendance on average. Christmas had lower than average attendance, while Boxing Day to New Year's Eve had greater attendance than what is seen in December and January. \n"
      ],
      "id": "fb025f05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-cal_attend\n",
        "#| fig-cap: Calendar Plot of Attendance\n",
        "#| warning: false\n",
        "\n",
        "attend_date = calendar_plot_data.groupby('month_day').mean()\n",
        "attend_date['count'] = attend_date['standard_attend']\n",
        "attend_date = attend_date['count'].sort_values().reset_index()\n",
        "attend_date['total_date'] = '2024-' + attend_date['month_day']\n",
        "\n",
        "attend_date['total_date'] = pd.to_datetime(attend_date['total_date'], format = \"%Y-%m-%d\")\n",
        "events = pd.Series(attend_date['count'].values.tolist(), index = attend_date['total_date'].values.tolist())\n",
        "july.heatmap(dates = attend_date['total_date'], data = attend_date['count'],  cmap='RdYlBu', date_label = True, fontsize =10, weekday_label=False, year_label= False, title = 'Avg Attendance per day Standardized 2010-2019', colorbar= True, dpi =1200)\n",
        "plt.show()"
      ],
      "id": "fig-cal_attend",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Away Team Impact\n",
        "\n",
        "The next factor viewed is the impact of the away team. We are looking at how who the away team impacts the attendance of the home team. For this, the standardized attendance was grouped by all the away teams and then averaged. The results can be seen below. You can select what leagues you would like to view and the top number of teams from that league. \n"
      ],
      "id": "63dcc14e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "\n",
        "away_team_impact = total_data.groupby(['away_team', 'division'])['standard_attend'].mean().reset_index()\n",
        "\n",
        "\n",
        "# away_team_impact = away_team_impact[away_team_impact['division'].isin(['E3', 'E1', 'E2'])]\n",
        "div_dict = {'D1':'Bundesliga', 'D2': '2. Bundesliga', 'E0':'Premier League', 'E1':'Championship', \n",
        "            'E2':'League 1', 'E3':'Leauge 2','SP1':'La Liga Primera', 'SP2':'La Liga Segunda',\n",
        "              'B1':'Jupiler League', 'F1':'Ligue 1','F2':'Ligue 2','I1':'Serie A','I2':'Seire B', \n",
        "              'SC0':'Scotish Premier League', 'SC1':'Scotish Division 1', 'T1':'Fubol Ligi 1', 'P1': 'Liga 1'}\n",
        "divisions_list =['D1', 'D2', 'E0', 'E1', 'E2', 'E3', 'SP1' ,'SP2', 'B1', 'F1', 'F2', 'I1', 'I2', 'SC0', 'SC1', 'T1', 'P1']\n",
        "\n",
        "away_team_impact = away_team_impact[['away_team', 'division', 'standard_attend']]\n",
        "# print(away_team_impact)\n",
        "initial_graph_df = pd.DataFrame(columns = ['away_team', 'division', 'standard_attend'])\n",
        "\n",
        "for i in divisions_list:\n",
        "        temp_impact_df = away_team_impact[away_team_impact['division'] == i].sort_values('standard_attend',ascending = False).head(3)\n",
        "        initial_graph_df = pd.concat([initial_graph_df, temp_impact_df], axis = 0)\n",
        "\n",
        "\n",
        "# fig = go.Figure(px.bar(away_team_impact, y= 'away_team', x = 'standard_attend', color = 'division'))\n",
        "\n",
        "app = JupyterDash(__name__)\n",
        "app.layout = html.Div(id = 'parent', children = [\n",
        "    html.H1(id = 'H1', children = 'Away Team Impact'),\n",
        "    dcc.Slider(0,20,1, value =3,id = 'slider'),\n",
        "    dcc.Dropdown(id = 'dropdown', \n",
        "                 options = [\n",
        "                {'label': 'Bundesliga', 'value':'D1'},\n",
        "                {'label': '2. Bundesliga', 'value':'D2'},\n",
        "                {'label': 'Premier League', 'value':'E0'},\n",
        "                {'label': 'Championship', 'value':'E1'},\n",
        "                {'label': 'League 1', 'value':'E2'},\n",
        "                {'label': 'Leauge 2', 'value':'E3'},\n",
        "                {'label': 'La Liga Primera', 'value':'SP1'},\n",
        "                {'label': 'La Liga Segunda', 'value':'SP2'},\n",
        "                {'label': 'Jupiler League', 'value':'B1'},\n",
        "                {'label': 'Ligue 1', 'value':'F1'},\n",
        "                {'label': 'Ligue 2', 'value':'F2'},\n",
        "                {'label': 'Serie A', 'value':'I1'},\n",
        "                {'label': 'Serie B', 'value':'I2'},\n",
        "                {'label': 'Scotish Premier League', 'value':'SC0'},\n",
        "                {'label': 'Scotish Division 1', 'value':'SC1'},\n",
        "                {'label': 'Fubol Ligi 1', 'value':'T1'},\n",
        "                {'label': 'Liga 1', 'value':'P1'}\n",
        "\n",
        "\n",
        "                 ], value = ['D1', 'D2', 'E0', 'E1', 'E2', 'E3', 'SP1' ,'SP2', 'B1', 'F1', 'F2', 'I1', 'I2', 'SC0', 'SC1', 'T1', 'P1'],\n",
        "                 multi = True),\n",
        "    dcc.Graph(id = 'bar_plot', figure=px.bar(initial_graph_df.replace({'division':div_dict}), x='away_team', y='standard_attend', color='division'))\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"bar_plot\", \"figure\"), \n",
        "    [Input(\"dropdown\", \"value\"),\n",
        "     Input('slider', 'value')]\n",
        "    )\n",
        "def update_graph(drop_value, slider_value):\n",
        "    # print(value)\n",
        "    df = away_team_impact\n",
        "\n",
        "    \n",
        "\n",
        "    df = df[df['division'].isin(list(drop_value))]\n",
        "    graph_df = pd.DataFrame(columns = ['away_team', 'division', 'standard_attend'])\n",
        "    for i in drop_value:\n",
        "        temp_impact_df = df[df['division'] == i].sort_values('standard_attend',ascending = False).head(slider_value)\n",
        "        graph_df = pd.concat([graph_df, temp_impact_df], axis = 0)\n",
        "    graph_df = graph_df.reset_index().drop(columns = ['index']).replace({'division':div_dict})\n",
        "    fig = px.bar(graph_df, x= 'away_team', y= 'standard_attend', color = 'division')\n",
        "    return fig\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(mode='inline')"
      ],
      "id": "8459b463",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Top Teams in the Biggest Leagues\n"
      ],
      "id": "dcb1a29f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "away_team_top_3 = pd.DataFrame(columns = ['away_team', 'division', 'standard_attend'])\n",
        "\n",
        "\n",
        "for i in divisions_list:\n",
        "        temp_impact_df = away_team_impact[away_team_impact['division'] == i].sort_values('standard_attend',ascending = False).head(3)\n",
        "        away_team_top_3 = pd.concat([away_team_top_3, temp_impact_df], axis = 0)\n"
      ],
      "id": "255ce277",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In @fig-top_away_league, it views the top 3 teams with the greatest impact on attendance in the top league in Germany, England, Spain, France, and Italy. The teams with the greatest impact on the home team's attendance are all big-name teams that are globally marketed. They have historical and current success within the league. For instance, in La Liga Primera, the three teams, Real Madrid, FC Barcelona, and Atletico Madrid, are the only teams that have won the league since 2004 [@sportskeeda]. Similar things can be seen in the other leagues. The teams that have a history of success and currently are succeeding have the greatest impact. Additionally, these teams are the ones globally marketed to the world. \n"
      ],
      "id": "d6d52971"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-top_away_league\n",
        "#| fig-cap: 'Greatest Away teams Impact on Attendance: First Divisions'\n",
        "top_league_away = away_team_top_3[away_team_top_3['division'].isin(['E0', 'I1', 'F1', 'SP1', 'D1'])].replace({'division':div_dict})\n",
        "\n",
        "sns.barplot(data = top_league_away, x = 'standard_attend', y = 'away_team', hue = 'division', dodge = False)\n",
        "plt.title('Away Teams Impact on Attendance: Top 3 teams per Top League')\n",
        "plt.xlabel('Mean Attendnace Increase')\n",
        "plt.ylabel('Away Team')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "plt.show()"
      ],
      "id": "fig-top_away_league",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Greatest Away Team Impact - English Leagues\n",
        "\n",
        "Looking at teams in lower leagues, similar trends appear. @fig-england_away shows the lower leagues in England. All of the teams stated here have had historical success. For some of the teams, such as Leeds and Coventry City, the success was in the past. Coventry City was in the top division of English Football from 1967 to 2001, Winning the FA Cup in 1968. Leeds United is an even better example of historic success, winning the first division in the 1968-69, 1973-74, and 1991-92 seasons. Both of these teams have had historical success in their past however have found hard times as performances have declined in the modern era, forcing them to drop leagues. Other teams here, such as Newcastle, West Ham United, and Sunderland, were at the top level of football during this time period. However, got relegated to one or two leagues during that time. However, with that, they still have an increase in attendance. So Teams that have had historical success or recently got relegated from higher leagues are seen to have an impact on the home team's attendance. \n"
      ],
      "id": "3d5dd040"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-england_away\n",
        "#| fig-cap: Top 3 Away Teams per English League\n",
        "top_england_away = away_team_top_3[away_team_top_3['division'].isin(['E0', 'E1', 'E2', 'E3'])].replace({'division':div_dict})\n",
        "\n",
        "sns.barplot(data = top_england_away, x = 'standard_attend', y = 'away_team', hue = 'division', dodge = False)\n",
        "plt.title('Away Teams Impact on Attendance: Top 3 teams per English League')\n",
        "plt.xlabel('Mean Attendnace Increase')\n",
        "plt.ylabel('Away Team')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
        "plt.show()"
      ],
      "id": "fig-england_away",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Betting Odds\n",
        "\n",
        "The final factor used in evaluating attendance was the betting odds for an individual match. Betting odds were used as a method to show favorability and predicted results of a match. It shows the current perceived strength of each team. \n",
        "\n",
        "\n",
        "## Comparing Betting Data Sources\n",
        "\n",
        "The dataset gathered had multiple different sources of betting odds. Some were removed before the final dataset due to too many N/A values, but the betting company's sources that remained were Bet365, Bet&Win, William Hill, and VC Bet. In viewing the heatmaps seen in @fig-betting_comp, there was little difference in how the betting sites predicted and the actual results of the game. Due to this, we assume that all the betting data are comparable. For the remainder of the project, Bet 365 is used because it had one of the fewest numbers of missing values still, and it's easily available. \n"
      ],
      "id": "3e416584"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bet_dataset = total_data[['raw_attendance', 'division', 'FTR',\n",
        "        'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'WHH', 'WHD',\n",
        "       'WHA', 'VCH', 'VCD', 'VCA', 'BbMx>2.5', 'BbAv>2.5', 'BbMx<2.5',\n",
        "       'BbAv<2.5']]\n",
        "\n",
        "b365_conditions = [(bet_dataset['B365H'] < bet_dataset['B365A']) & (bet_dataset['B365H'] < bet_dataset['B365D']),\n",
        "                   (bet_dataset['B365A'] < bet_dataset['B365H']) & (bet_dataset['B365A'] < bet_dataset['B365D']),\n",
        "                   (bet_dataset['B365D'] < bet_dataset['B365A']) & (bet_dataset['B365D'] < bet_dataset['B365H'])]\n",
        "\n",
        "b365_vals = ['H', 'A', 'D']\n",
        "bet_dataset['B365_Result'] = np.select(b365_conditions,b365_vals)\n",
        "\n",
        "bw_conditions = [(bet_dataset['BWH'] < bet_dataset['BWA']) & (bet_dataset['BWH'] < bet_dataset['BWD']),\n",
        "                   (bet_dataset['BWA'] < bet_dataset['BWH']) & (bet_dataset['BWA'] < bet_dataset['BWD']),\n",
        "                   (bet_dataset['BWD'] < bet_dataset['BWA']) & (bet_dataset['BWD'] < bet_dataset['BWH'])]\n",
        "\n",
        "bw_vals = ['H', 'A', 'D']\n",
        "bet_dataset['BW_Result'] = np.select(bw_conditions,bw_vals)\n",
        "\n",
        "wh_conditions = [(bet_dataset['WHH'] < bet_dataset['WHA']) & (bet_dataset['WHH'] < bet_dataset['WHD']),\n",
        "                   (bet_dataset['WHA'] < bet_dataset['WHH']) & (bet_dataset['WHA'] < bet_dataset['WHD']),\n",
        "                   (bet_dataset['WHD'] < bet_dataset['WHA']) & (bet_dataset['WHD'] < bet_dataset['WHH'])]\n",
        "\n",
        "wh_vals = ['H', 'A', 'D']\n",
        "bet_dataset['WH_Result'] = np.select(wh_conditions,wh_vals)\n",
        "\n",
        "vc_conditions = [(bet_dataset['VCH'] < bet_dataset['VCA']) & (bet_dataset['VCH'] < bet_dataset['VCD']),\n",
        "                   (bet_dataset['VCA'] < bet_dataset['VCH']) & (bet_dataset['VCA'] < bet_dataset['VCD']),\n",
        "                   (bet_dataset['VCD'] < bet_dataset['VCA']) & (bet_dataset['VCD'] < bet_dataset['VCH'])]\n",
        "\n",
        "vc_vals = ['H', 'A', 'D']\n",
        "bet_dataset['VC_Result'] = np.select(vc_conditions,vc_vals)\n"
      ],
      "id": "89b38490",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-betting_comp\n",
        "#| fig-cap: Betting Predicting Results of Matches\n",
        "#| warning: false\n",
        "\n",
        "def betting_accuracy_vis(name, axis):\n",
        "    b365_data = bet_dataset[[name, 'FTR']].dropna()\n",
        "    # print(b365_data[name].value_counts())\n",
        "    b365_data = b365_data[b365_data[name]!= '0']\n",
        "    b365_data = b365_data.groupby(['FTR',name]).size()\n",
        "    b365_data = b365_data.reset_index(name = 'count')\n",
        "    FTR_result = b365_data[[name,'count']].rename(columns = {'count':'total'})\n",
        "    FTR_result = FTR_result.groupby([name]).sum().reset_index()\n",
        "    # print(FTR_result)\n",
        "    b365_data = pd.merge(b365_data, FTR_result, on =name)\n",
        "    total_count = b365_data['count'].sum()\n",
        "    # print(total_count)\n",
        "    b365_data['pct'] = b365_data['count']/b365_data['total'] *100\n",
        "    # print(b365_data)\n",
        "    b365_data = b365_data.pivot(index = 'FTR', columns = name, values = 'pct')\n",
        "    # print(b365_data)\n",
        "\n",
        "    fig = sns.heatmap(data = b365_data, annot= True, ax = axis)\n",
        "    # plt.title(name + ' Accuracy in predicting Actual Result')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "result_name_list = ['B365_Result', 'BW_Result', 'WH_Result', 'VC_Result']\n",
        "# for i in result_name_list:\n",
        "#     betting_accuracy_vis(i)\n",
        "figure, ax = plt.subplots(2,2)\n",
        "\n",
        "betting_accuracy_vis('B365_Result', ax[0,0])\n",
        "betting_accuracy_vis('BW_Result', ax[0,1])\n",
        "betting_accuracy_vis('WH_Result', ax[1,0])\n",
        "betting_accuracy_vis('VC_Result', ax[1,1])\n",
        "plt.title('Betting Data Compared to Actual Match Result')\n",
        "plt.show()"
      ],
      "id": "fig-betting_comp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Betting Odds\n",
        "\n",
        "The @fig-home_fav shows what occurs to attendance when the home team is favored to win. @fig-home_fav is using the entire dataset from 2010 to 2019. What classify in this graph is an increase in attendance for every match; if the standard_attend was positive or equal, it was classified as increasing the attendance in relation to the home team attendance for that season, and if it was negative, decreasing the attendance. The home team favored is using Bet365 odds. If the betting odds of the home team winning was a smaller number than the betting odds for the away team winning, then it was put that the home team was favored. And if the home team betting odds were greeted then the away team betting odds, then it was put as not favored. When the Home team is favored, the games will typically have less than-average attendance for that match. However, if the Home team is not favored, the matches are more likely to have a greater-than-average season attendance for the match. This could demonstrate that fans like to see underdog performances, and if their team is favored, they do not view it as an important match. \n"
      ],
      "id": "241d6dbc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-home_fav\n",
        "#| fig-cap: Impact of Home team favoriability to win on Attendance\n",
        "bet_data = total_data\n",
        "bet_data = bet_data.dropna(subset = ['B365H', 'B365A'])\n",
        "h_fav = []\n",
        "attend_increase = []\n",
        "for index, rows in bet_data.iterrows():\n",
        "    if rows['B365H'] < rows['B365A']:\n",
        "        h_fav = h_fav + [True]\n",
        "    else:\n",
        "        h_fav = h_fav + [False]\n",
        "    if rows['standard_attend'] >= 0:\n",
        "        attend_increase = attend_increase + [True]\n",
        "    else:\n",
        "        attend_increase = attend_increase + [False]\n",
        "# print(h_fav)\n",
        "        \n",
        "bet_increase_bool = bet_data\n",
        "bet_increase_bool['home_fav'] = h_fav\n",
        "bet_increase_bool['attend_increase'] = attend_increase\n",
        "bet_bool = bet_increase_bool[['home_fav', 'attend_increase','raw_attendance']]\n",
        "bet_bool = bet_bool.groupby(['home_fav', 'attend_increase']).count().reset_index().rename(columns = {'home_fav':'Home Team Favorited', 'attend_increase':'Increase In Attendance'})\n",
        "# total_matches = sum(bet_bool['raw_attendance'])\n",
        "# bet_bool['raw_attendance'] = bet_bool['raw_attendance'] *100/total_matches\n",
        "\n",
        "# print(bet_bool)\n",
        "# print(total_matches)\n",
        "count_pct = []\n",
        "for index, rows in bet_bool.iterrows():\n",
        "    # print('----------')\n",
        "    goals = rows['Home Team Favorited']\n",
        "    # print(goals)\n",
        "    total_count_goals = bet_bool[bet_bool['Home Team Favorited'] == goals]['raw_attendance'].values\n",
        "    total_count_goals = sum(total_count_goals)\n",
        "    # print(total_count_goals)\n",
        "    percent_total = rows['raw_attendance']*100/total_count_goals\n",
        "    # print(percent_total)\n",
        "    count_pct = count_pct + [percent_total]\n",
        "bet_bool['pcnt_values']  = count_pct\n",
        "\n",
        "\n",
        "# bet_bool = bet_bool.pivot_table(values = 'pcnt_values', index = 'Home Team Favorited', columns = 'Increase In Attendance')\n",
        "# print(bet_bool)\n",
        "\n",
        "# sns.heatmap(bet_bool,annot= True)\n",
        "sns.barplot(data =bet_bool, x = 'Home Team Favorited', y = 'pcnt_values', hue = 'Increase In Attendance')\n",
        "\n",
        "plt.gca().invert_xaxis()\n",
        "# plt.gca().invert_yaxis()\n",
        "plt.title('Attendance Impact depending if Home Team is Favored')\n",
        "plt.ylabel('Percent')\n",
        "plt.show()"
      ],
      "id": "fig-home_fav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Odds of Goals > 2.5\n",
        "\n",
        "The @fig-goals shows How does attendance change when there are more goals predicted to occur. The odds of goals over 2.5 was created. This graph shows that when the betting odds of over 2.5 goals are smaller than the betting odds of less than 2.5 goals, then the game is favored to have over 2.5 goals scored. The data used to determine this is the columns BbAV >2.5 and BbAV<2.5. What resulted is that when the match is expected to be a higher scoring match, the attendance being greater compared to less than average is even. However, when the match is not favored to have over 2.5 goals scored, the attendance is more likely to be negatively impacted in relation to the season average. \n"
      ],
      "id": "34c436ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-goals\n",
        "#| fig-cap: Predicted Goals in relation to attendance\n",
        "goal_data = total_data.dropna(subset = ['standard_attend', 'BbAv>2.5','BbAv<2.5'])\n",
        "# print(data)\n",
        "\n",
        "increase_attend = []\n",
        "higher_goals = []\n",
        "for index, rows in goal_data.iterrows():\n",
        "    if rows['standard_attend'] >=0:\n",
        "        increase_attend = increase_attend + [True]\n",
        "    else:\n",
        "        increase_attend = increase_attend + [False]\n",
        "    if rows['BbAv>2.5'] <= rows['BbAv<2.5']:\n",
        "        higher_goals = higher_goals + [True]\n",
        "    else:\n",
        "        higher_goals = higher_goals +[False]\n",
        "# print(increase_attend)\n",
        "\n",
        "goal_data['increase_attend'] = increase_attend\n",
        "goal_data['higher_goals'] = higher_goals\n",
        "# print(data)\n",
        "\n",
        "df = goal_data[['higher_goals', 'increase_attend']]\n",
        "df = df.value_counts().reset_index(name= 'count')\n",
        "count_pct = []\n",
        "df_grouped_higher_goal_sum = df.groupby('higher_goals')['count'].sum().reset_index()\n",
        "# print(df_grouped_higher_goal_sum)\n",
        "\n",
        "\n",
        "for index, rows in df.iterrows():\n",
        "    # print('----------')\n",
        "    goals = rows['higher_goals']\n",
        "    # print(goals)\n",
        "    total_count_goals = df_grouped_higher_goal_sum[df_grouped_higher_goal_sum['higher_goals'] == goals]['count'].values\n",
        "    total_count_goals = sum(total_count_goals)\n",
        "    # print(total_count_goals)\n",
        "    percent_total = rows['count']*100/total_count_goals\n",
        "    # print(percent_total)\n",
        "    count_pct = count_pct + [percent_total]\n",
        "df['count_pct'] = count_pct\n",
        "# total_count = df['count'].sum()\n",
        "# df['pct'] = df['count']*100/total_count\n",
        "df = df.rename(columns = {'higher_goals':'Odds of Goals over 2.5 is greater', 'increase_attend': 'Increased Attendance'})\n",
        "df2 = df.pivot(index = 'Odds of Goals over 2.5 is greater', columns = 'Increased Attendance', values = 'count_pct')\n",
        "# print(df)\n",
        "# sns.heatmap(goal_data = df2, annot= True)\n",
        "# plt.gca().invert_xaxis()\n",
        "# plt.gca().invert_yaxis()\n",
        "# plt.title('Predicted Goals in relation to Attendance')\n",
        "# plt.show()\n",
        "sns.barplot(data =df, x = 'Odds of Goals over 2.5 is greater', y = 'count_pct', hue = 'Increased Attendance')\n",
        "plt.gca().invert_xaxis()\n",
        "plt.ylabel('Percent')\n",
        "plt.title('Predicted Goals in relation to Attendance')\n",
        "plt.show()"
      ],
      "id": "fig-goals",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modeling\n",
        "\n",
        "All of this analysis and looking at different factors that would impact attendance leads to predicting the attendance of a game. With the complexity of the data a random forest regression model was implemented. Random Forest Regression is a supervised machine learning model. It uses multiple decsision trees to make the best model for the data. \n"
      ],
      "id": "008fc50f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_dataset = total_data\n",
        "model_dataset = model_dataset.dropna(subset = ['B365A', 'BWH', 'WHH', 'VCD','BbMx>2.5',\n",
        "                             'BbAv>2.5', 'BbMx<2.5', 'BbAv<2.5', 'std_attend', 'standard_attend'])\n",
        "model_dataset = model_dataset.drop(['date_time'], axis =1)\n",
        "obj_data = model_dataset.select_dtypes(include=['object']).copy()\n",
        "column_obj_name = obj_data.columns.values.tolist()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "\n",
        "for obj in column_obj_name:\n",
        "    model_dataset[obj] = label_encoder.fit_transform(model_dataset[obj])\n",
        "model_dataset = model_dataset.astype(float)\n",
        "model_dataset = model_dataset.dropna()\n",
        "\n",
        "\n",
        "x = model_dataset.drop(['raw_attendance', 'standard_attend'], axis = 1)\n",
        "x = x[['home_team', 'away_team', 'division', 'date', 'time', 'day_of_week','B365H', 'B365D',\n",
        "       'B365A']]\n",
        "y = model_dataset['raw_attendance']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .2, random_state = 11)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Random Forest\n",
        "# The Random Forest Model was Performed outside the file and will be imported into the document. \n",
        "#  ------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "random_forest_model = RandomForestRegressor(n_estimators = 1000, random_state= 23)\n",
        "\n",
        "random_forest_model.fit(x_train, y_train)\n",
        "#  ------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# load_random_forest_model = pickle.load(open('../src/Modeling/Random_forest_model.sav', 'rb'))\n"
      ],
      "id": "6fc10707",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_predict = random_forest_model.predict(x_test)"
      ],
      "id": "555ee776",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mae = metrics.mean_absolute_error(y_test, y_predict)\n",
        "mse = metrics.mean_squared_error(y_test, y_predict)\n",
        "mape = metrics.mean_absolute_percentage_error(y_test, y_predict)\n",
        "r2 = metrics.r2_score(y_test, y_predict)\n",
        "result_df = pd.DataFrame(np.array([['Mean Absolute Error', mae], ['Mean Squared Error', mse],\n",
        "    ['Mean Absolute Percentage Error', mape], ['r\\u00b2', r2]]), columns = ['Metric', 'Score'])"
      ],
      "id": "e92bcf06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_df"
      ],
      "id": "418069ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Random Forest model used 1000 decsion trees to build it. The results of the model can be seen in the table above. \n"
      ],
      "id": "c79ee7f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_result = total_data[['raw_attendance']]\n",
        "model_result['predicted_attend'] = y_predict\n",
        "\n",
        "model_result.head()"
      ],
      "id": "f6180a9d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}